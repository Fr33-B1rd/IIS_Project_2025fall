import torch
import torch.nn as nn
import torch.optim as optim
from torchvision import datasets, transforms
from torch.utils.data import DataLoader, Subset
import os

# --- CONFIG ---
DATA_PATH = "./dataset/DiffusionFER/DiffusionEmotion_S/original"
MODEL_SAVE_PATH = "./models/emotion_classifier.pth"
BATCH_SIZE = 32
EPOCHS = 10

# --- NEW MAPPING LOGIC ---
# We map multiple source folders to a single target index.
# 0 = Excited
# 1 = Nervous
# 2 = Confused
LABEL_MAPPING = {
    "happy": 0,
    "surprise": 0,  # Merged into Excited
    
    "fear": 1,
    "sad": 1,       # Merged into Nervous
    
    "neutral": 2    # Mapped to Confused
}

class SimpleEmotionMLP(nn.Module):
    def __init__(self, input_dim=384, num_classes=3): 
        super().__init__()
        self.layers = nn.Sequential(
            nn.Linear(input_dim, 128),
            nn.ReLU(),
            nn.Dropout(0.2),
            nn.Linear(128, 64),
            nn.ReLU(),
            nn.Linear(64, num_classes)
        )

    def forward(self, x):
        return self.layers(x)

def train():
    device = "cuda" if torch.cuda.is_available() else "cpu"
    print(f"Training on {device}...")

    # Load DINOv2
    dino = torch.hub.load('facebookresearch/dinov2', 'dinov2_vits14').to(device)
    dino.eval()

    # Transforms
    transform = transforms.Compose([
        transforms.Resize((224, 224)),
        transforms.ToTensor(),
        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
    ])

    # Load Dataset
    full_dataset = datasets.ImageFolder(root=DATA_PATH, transform=transform)

    indices = []
    new_targets = []
    
    print("Applying custom label mapping...")
    for idx, (path, label_idx) in enumerate(full_dataset.samples):
        folder_name = full_dataset.classes[label_idx] # e.g., 'neutral', 'sad'
        
        # Only use images that match our map
        if folder_name in LABEL_MAPPING:
            indices.append(idx)
            new_targets.append(LABEL_MAPPING[folder_name])

    # Create Subset
    filtered_dataset = Subset(full_dataset, indices)
    
    # Custom Dataset Wrapper to override labels
    class MappedDataset(torch.utils.data.Dataset):
        def __init__(self, subset, new_labels):
            self.subset = subset
            self.new_labels = new_labels
        def __len__(self): return len(self.subset)
        def __getitem__(self, idx):
            img, _ = self.subset[idx]
            return img, self.new_labels[idx]

    train_data = MappedDataset(filtered_dataset, new_targets)
    loader = DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True)
    
    print(f"Training on {len(train_data)} images.")

    # Training Loop
    classifier = SimpleEmotionMLP().to(device)
    optimizer = optim.Adam(classifier.parameters(), lr=0.001)
    criterion = nn.CrossEntropyLoss()

    for epoch in range(EPOCHS):
        total_loss = 0
        correct = 0
        
        for images, labels in loader:
            images, labels = images.to(device), labels.to(device)
            
            with torch.no_grad():
                features = dino(images)
            
            optimizer.zero_grad()
            outputs = classifier(features)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            
            total_loss += loss.item()
            _, preds = torch.max(outputs, 1)
            correct += (preds == labels).sum().item()
            
        acc = correct / len(train_data)
        print(f"Epoch {epoch+1}/{EPOCHS} | Loss: {total_loss:.4f} | Acc: {acc*100:.1f}%")

    os.makedirs("models", exist_ok=True)
    torch.save(classifier.state_dict(), MODEL_SAVE_PATH)
    print(f"Model saved to {MODEL_SAVE_PATH}")

if __name__ == "__main__":
    train()